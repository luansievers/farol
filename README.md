# ğŸ” Farol

### Civic Infrastructure for Public Contract Analysis

ğŸŒ **Read in:** [English](README.md) | [PortuguÃªs](README.pt-BR.md)

[![License: GPL-3.0](https://img.shields.io/badge/license-GPL--3.0-blue.svg)](LICENSE)
[![Node.js >= 20](https://img.shields.io/badge/node-20+-green)](package.json)
[![TypeScript](https://img.shields.io/badge/typescript-5.9-blue)](tsconfig.json)
[![PostgreSQL >= 14](https://img.shields.io/badge/postgresql-14+-blue)](README.md)
[![Made with React](https://img.shields.io/badge/made_with-React-61dafb)](packages/web/package.json)

Farol transforms technical public contract documents from SÃ£o Paulo's government into accessible, analyzable information using AI-powered analysis, automated risk detection, and full-text search.

---

## ğŸ“¸ Screenshots

<table>
  <tr>
    <td><img src="docs/press-kit/screenshots/01-dashboard.png" alt="Dashboard with analytics" /></td>
    <td><img src="docs/press-kit/screenshots/02-contratos-lista.png" alt="Contracts list view" /></td>
  </tr>
  <tr>
    <td><img src="docs/press-kit/screenshots/03-contrato-detalhe.png" alt="Contract details" /></td>
    <td><img src="docs/press-kit/screenshots/04-contrato-anomalia.png" alt="Anomaly detection" /></td>
  </tr>
  <tr>
    <td><img src="docs/press-kit/screenshots/05-busca-global.png" alt="Global search" /></td>
    <td><img src="docs/press-kit/screenshots/06-fornecedor-detalhe.png" alt="Supplier profile" /></td>
  </tr>
  <tr>
    <td><img src="docs/press-kit/screenshots/07-orgao-detalhe.png" alt="Agency profile" /></td>
    <td><img src="docs/press-kit/screenshots/08-dark-mode.png" alt="Dark mode interface" /></td>
  </tr>
</table>

---

## ğŸ¯ Problem & Mission

Public contracts in Brazil involve billions of taxpayer reais annually, but accessing and understanding this data is difficult for citizens. Contract documents are technical, scattered, and lack contextual analysis.

**Farol's mission**: Bridge the transparency gap by making public procurement data accessible, searchable, and understandable through AI-powered analysis and anomaly detection.

---

## âœ¨ Key Features

### ğŸ¤– **AI-Powered Summaries**
Automatic generation of plain-language summaries from complex contract documents using LLMs (OpenAI/Anthropic).

### ğŸš¨ **Anomaly Detection**
Automated risk scoring based on 8 criteria:
- Price outliers
- Amendment frequency
- Single-bid contracts
- Emergency procurement
- Supplier risk flags
- Execution delays
- Value concentration
- Historical patterns

### ğŸ” **Full-Text Search**
Fast, PostgreSQL-backed search across all contracts, suppliers, and agencies with relevance ranking.

### ğŸ“Š **Analytics Dashboard**
Visualize spending trends, top suppliers, agency activity, and risk distributions.

### ğŸ”Œ **REST API**
Open API for programmatic access to all contract data, summaries, and analytics.

---

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** >= 20
- **pnpm** >= 9
- **PostgreSQL** >= 14
- **Docker** (optional, for local DB)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/luansievers/farol.git
   cd farol
   ```

2. **Install dependencies**
   ```bash
   pnpm install
   ```

3. **Configure environment**
   ```bash
   cp packages/api/.env.example packages/api/.env
   # Edit packages/api/.env with your settings
   ```

   **Required environment variables**:
   - `DATABASE_URL` - PostgreSQL connection string
   - `AI_PROVIDER` - "openai" or "anthropic"
   - `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`
   - `STORAGE_*` - S3/MinIO configuration

4. **Setup database**
   ```bash
   pnpm db:migrate    # Run migrations
   pnpm db:seed       # Seed initial data (optional)
   ```

5. **Start development servers**
   ```bash
   pnpm dev:all       # API (port 3000) + Web (port 5173)
   ```

### Docker Option

```bash
docker-compose up -d   # Starts PostgreSQL + MinIO
pnpm install
pnpm db:migrate
pnpm dev:all
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Public Web UI        â”‚
â”‚   (React + Vite)       â”‚  â† User-facing interface
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   REST API (Hono)      â”‚  â† /api/contracts, /api/search
â”‚   Zod + OpenAPI        â”‚     /api/suppliers, /api/agencies
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Pipeline (ETL)  â”‚  â† crawler â†’ detail â†’ parser
â”‚   8-stage workflow     â”‚     â†’ summary â†’ classify â†’ anomaly
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”
    â”‚      â”‚      â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â” â”Œâ”€â–¼â”€â”€â” â”Œâ–¼â”€â”€â”€â”
â”‚ DB   â”‚ â”‚ S3 â”‚ â”‚LLM â”‚
â”‚Prismaâ”‚ â”‚/MINâ”‚ â”‚APIsâ”‚  â† PostgreSQL, MinIO, OpenAI/Anthropic
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
```

### Monorepo Structure

```
packages/
â”œâ”€â”€ api/           # Hono backend + Prisma ORM
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ modules/    # Feature modules
â”‚   â”‚   â”‚   â”œâ”€â”€ api/        # REST endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ crawler/    # PNCP data fetching
â”‚   â”‚   â”‚   â”œâ”€â”€ parser/     # PDF text extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ summary/    # AI summarization
â”‚   â”‚   â”‚   â”œâ”€â”€ classification/ # Categorization
â”‚   â”‚   â”‚   â”œâ”€â”€ anomalies/  # Risk scoring
â”‚   â”‚   â”‚   â”œâ”€â”€ database/   # Prisma client
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/    # S3/MinIO
â”‚   â”‚   â”‚   â””â”€â”€ ai/         # LLM utilities
â”‚   â”‚   â””â”€â”€ generated/  # Prisma types
â”‚   â””â”€â”€ prisma/
â”‚       â””â”€â”€ schema.prisma
â”œâ”€â”€ web/           # React + TanStack Router/Query
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/      # File-based routing
â”‚   â”‚   â”œâ”€â”€ components/  # UI components (shadcn/ui)
â”‚   â”‚   â”œâ”€â”€ hooks/       # TanStack Query hooks
â”‚   â”‚   â””â”€â”€ lib/         # Utilities
â””â”€â”€ shared/        # Shared TypeScript types
    â””â”€â”€ src/
        â”œâ”€â”€ dtos/    # Data Transfer Objects
        â””â”€â”€ enums/   # Shared enums
```

---

## ğŸ“¡ API Documentation

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/contracts` | GET | List contracts with pagination/filters |
| `/api/contracts/:id` | GET | Get contract details + amendments |
| `/api/contracts/search` | GET | Full-text search |
| `/api/suppliers` | GET | List suppliers with stats |
| `/api/suppliers/:id` | GET | Supplier profile + contracts |
| `/api/agencies` | GET | List government agencies |
| `/api/agencies/:id` | GET | Agency profile + contracts |
| `/api/stats` | GET | Platform-wide statistics |

### Example Request

```bash
curl "http://localhost:3000/api/contracts?page=1&limit=20&status=active"
```

### Example Response

```json
{
  "data": [
    {
      "id": "abc123",
      "number": "001/2024",
      "title": "ServiÃ§os de TI",
      "value": 500000.00,
      "supplier": { "id": "xyz", "name": "Tech Corp" },
      "agency": { "id": "def", "name": "PMSP" },
      "summary": "Contract for IT infrastructure services...",
      "anomalyScore": 65,
      "riskLevel": "MEDIUM"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 20,
    "total": 1542
  }
}
```

### Anomaly Score Criteria

| Criterion | Description | Weight |
|-----------|-------------|--------|
| **Price Outlier** | Value 2+ standard deviations above category average | High |
| **Amendment Frequency** | More than 3 amendments (limit is 25% of value per law) | High |
| **Single Bidder** | Only one supplier participated in bidding | Medium |
| **Emergency Procurement** | Contract used emergency justification | Medium |
| **Supplier Risk** | Supplier has history of penalties/cancellations | High |
| **Execution Delay** | Contract execution delayed beyond 30 days | Low |
| **Value Concentration** | Supplier receives >10% of agency's total contracts | Medium |
| **Historical Pattern** | Deviation from agency's typical spending patterns | Low |

**Score ranges**:
- **0-30**: Low risk (green)
- **31-60**: Medium risk (yellow)
- **61-100**: High risk (red)

### OpenAPI Documentation

Interactive API docs available at: `http://localhost:3000/doc` (Swagger UI)

---

## ğŸ”„ Data Pipeline (ETL)

### Workflow

```
1. crawler    â†’ Fetch contract list from PNCP API
2. detail     â†’ Fetch detailed contract data
3. parser     â†’ Extract text from PDF documents (OCR via tesseract.js)
4. summary    â†’ Generate AI summaries
5. classify   â†’ Categorize contracts
6. anomaly    â†’ Calculate anomaly scores
```

### Commands

```bash
# Fetch contracts from PNCP
pnpm crawler              # Fetch new contracts
pnpm crawler:week         # Fetch last 7 days
pnpm crawler:month        # Fetch last 30 days

# Fetch contract details
pnpm detail               # Fetch details for pending contracts
pnpm detail:batch         # Process in batches
pnpm detail:stats         # Show processing statistics
pnpm detail:reset         # Reset processing status

# Parse PDFs
pnpm parser               # Parse pending PDFs
pnpm parser:batch         # Process in batches
pnpm parser:stats         # Show parsing statistics
pnpm parser:reset         # Reset parsing status

# Generate summaries
pnpm summary              # Generate summaries
pnpm summary:batch        # Process in batches
pnpm summary:stats        # Show summary statistics
pnpm summary:reset        # Reset summary status
pnpm summary:regen        # Regenerate existing summaries

# Classify contracts
pnpm classify             # Classify pending contracts
pnpm classify:batch       # Process in batches
pnpm classify:stats       # Show classification statistics
pnpm classify:reset       # Reset classification status
pnpm classify:reclassify  # Reclassify all contracts

# Calculate anomalies
pnpm anomaly              # Calculate scores
pnpm anomaly:batch        # Process in batches
pnpm anomaly:stats        # Show anomaly statistics
pnpm anomaly:reset        # Reset scores
pnpm anomaly:recalculate  # Recalculate all scores
pnpm anomaly:single <id>  # Calculate for single contract
```

### Automation

```bash
# Run full pipeline automatically
pnpm auto-update          # One-time full update
pnpm auto-update:start    # Start continuous updates
pnpm auto-update:stats    # Show update statistics
```

---

## ğŸ’» Development

### Available Scripts

```bash
# Development
pnpm dev:all       # Start API + web in parallel
pnpm dev           # API only (http://localhost:3000)
pnpm dev:web       # Web only (http://localhost:5173)

# Build & Quality
pnpm build         # Build all packages (shared â†’ api â†’ web)
pnpm test          # Run vitest tests
pnpm lint          # Lint all packages
pnpm typecheck     # Type check all packages

# Database
pnpm db:generate   # Generate Prisma client (run after schema changes)
pnpm db:migrate    # Create/run migrations
pnpm db:studio     # Open Prisma Studio UI
pnpm db:seed       # Seed database
pnpm db:reset      # Reset database (âš ï¸ deletes all data)
```

### Code Organization

**Path Aliases**:
- API: `@/*` â†’ `./src/*`, `@modules/*` â†’ `./src/modules/*`
- Web: `@/*` â†’ `./src/*`
- Both: `@farol/shared` â†’ shared package

**Module Structure** (API):
```
modules/
â””â”€â”€ feature-name/
    â”œâ”€â”€ controllers/       # HTTP handlers
    â”œâ”€â”€ services/          # Business logic
    â”œâ”€â”€ dto/
    â”‚   â”œâ”€â”€ request/       # Input DTOs
    â”‚   â””â”€â”€ response/      # Output DTOs
    â””â”€â”€ utils/             # Helper functions
```

**Component Structure** (Web):
```
src/
â”œâ”€â”€ routes/                # TanStack Router (file-based)
â”œâ”€â”€ components/            # UI components
â”‚   â”œâ”€â”€ ui/                # shadcn/ui primitives
â”‚   â””â”€â”€ feature-name/      # Feature components
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ queries/           # TanStack Query hooks
â””â”€â”€ lib/
    â”œâ”€â”€ validations/       # Zod schemas
    â””â”€â”€ api.ts             # API client
```

### Coding Standards

- **Language**: All code (functions, variables, comments, messages) in **English**
- **DTOs**: Separate request/response directories per module
- **Validation**: Zod schemas for API, class-validator for internal
- **Database**: Always run `pnpm db:generate` after Prisma schema changes
- **Type Safety**: Strict TypeScript, no `any`
- **Naming**: Descriptive, imperative for functions (`getUserById`, not `user`)

---

## ğŸ¤ Contributing

Contributions welcome! Areas of interest:

- ğŸ” **Data Sources**: Integrate CEIS, TCU, CNPJ data
- ğŸ“Š **Analytics**: Add new anomaly detection criteria
- ğŸ¨ **UI/UX**: Improve visualizations and user experience
- ğŸ§ª **Testing**: Increase test coverage
- ğŸ“– **Documentation**: Improve guides and API docs
- ğŸŒ **i18n**: Internationalization support

### Development Workflow

1. **Fork & clone** the repository
2. **Create a branch**: `git checkout -b feature/my-feature`
3. **Make changes**: Follow coding standards
4. **Test**: Run `pnpm test`, `pnpm lint`, `pnpm typecheck`
5. **Commit**: Use clear, imperative messages
   ```
   feat: add supplier network analysis
   fix: correct anomaly score calculation
   docs: update API documentation
   ```
6. **Push & PR**: Submit pull request with description

### Commit Message Format

```
<type>: <subject>

[optional body]
```

**Types**: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`

### PR Checklist

- [ ] Code follows project conventions
- [ ] Tests added/updated
- [ ] Documentation updated
- [ ] No type errors (`pnpm typecheck`)
- [ ] No linting errors (`pnpm lint`)
- [ ] Builds successfully (`pnpm build`)

---

## ğŸ—ºï¸ Roadmap

### Phase 1: Expanded Data Sources (Q1 2026)
- [ ] Integrate CEIS (Cadastro de Empresas InidÃ´neas)
- [ ] Connect TCU open data APIs
- [ ] Add CNPJ corporate network analysis
- [ ] Cross-reference supplier sanctions

### Phase 2: Advanced Analytics (Q2 2026)
- [ ] Supplier network visualization
- [ ] Temporal trend analysis
- [ ] Price prediction models
- [ ] Comparative benchmarking

### Phase 3: Community Features (Q3 2026)
- [ ] Public API with rate limiting
- [ ] Data export (CSV, JSON, Excel)
- [ ] Email alerts for flagged contracts
- [ ] User-submitted anomaly reports

### Phase 4: Institutional Integration (Q4 2026)
- [ ] Auditor dashboard with advanced filters
- [ ] Batch analysis tools
- [ ] White-label deployment option
- [ ] Integration with official oversight systems

---

## ğŸ› ï¸ Technology Stack

### Backend
- **Framework**: [Hono](https://hono.dev/) - Ultra-fast edge runtime
- **Database**: [PostgreSQL](https://www.postgresql.org/) + [Prisma ORM](https://www.prisma.io/)
- **Validation**: [Zod](https://zod.dev/) with OpenAPI generation
- **Storage**: S3-compatible (MinIO for local dev)
- **AI**: OpenAI GPT-4 / Anthropic Claude for summaries
- **Language**: TypeScript 5.9

### Frontend
- **Framework**: [React 19](https://react.dev/)
- **Routing**: [TanStack Router](https://tanstack.com/router)
- **State**: [TanStack Query](https://tanstack.com/query)
- **UI**: [shadcn/ui](https://ui.shadcn.com/) (Radix + Tailwind CSS)
- **Build**: [Vite 6](https://vite.dev/)

### DevOps
- **Monorepo**: pnpm workspaces
- **Testing**: Vitest
- **Linting**: ESLint + Prettier
- **CI/CD**: GitHub Actions (planned)
- **Containers**: Docker + Docker Compose

---

## ğŸš€ Deployment

### Option 1: Vercel + Railway

**Frontend (Vercel)**:
```bash
vercel deploy --prod
```

**Backend (Railway)**:
1. Connect GitHub repository
2. Set environment variables
3. Deploy from `packages/api`

### Option 2: Fly.io

```bash
fly deploy --config packages/api/fly.toml
```

### Option 3: Docker

```bash
# Build
docker build -t farol-api -f packages/api/Dockerfile .
docker build -t farol-web -f packages/web/Dockerfile .

# Run
docker-compose up -d
```

### Environment Variables (Production)

```bash
# Database
DATABASE_URL=postgresql://user:pass@host:5432/farol

# AI Provider
AI_PROVIDER=openai
OPENAI_API_KEY=sk-...

# Storage
STORAGE_PROVIDER=s3
STORAGE_ENDPOINT=https://s3.amazonaws.com
STORAGE_BUCKET=farol-documents
STORAGE_ACCESS_KEY=...
STORAGE_SECRET_KEY=...

# Security
JWT_SECRET=...
API_RATE_LIMIT=100
```

---

## â“ FAQ

**Q: How is user privacy handled?**
A: All data is public information from government sources (PNCP). We don't collect personal data from users.

**Q: What license is Farol under?**
A: GPL-3.0. You can use, modify, and distribute freely, but must open-source derivative works.

**Q: How often is data updated?**
A: Daily incremental updates. Full refresh weekly. Use `pnpm auto-update:start` for continuous updates.

**Q: Can I use Farol for commercial purposes?**
A: Yes, under GPL-3.0 terms. You must open-source any modifications.

**Q: Can I self-host Farol?**
A: Yes! See [Deployment](#-deployment) section. Requires PostgreSQL + Node.js.

**Q: How do I report security issues?**
A: Email security@farol.app (planned) or open a private GitHub advisory.

**Q: Why does AI summarization use paid APIs?**
A: Quality and reliability. We support both OpenAI and Anthropic. Local models (Ollama) planned.

---

## ğŸ“„ License & Credits

### License

Farol is licensed under **GPL-3.0**. See [LICENSE](LICENSE) for full text.

### Third-Party Licenses

- React: MIT
- Hono: MIT
- Prisma: Apache 2.0
- PostgreSQL: PostgreSQL License
- shadcn/ui: MIT
- TanStack: MIT

Full dependency licenses in `node_modules/*/LICENSE`.

### Data Sources

- **PNCP** (Plataforma Nacional de ContrataÃ§Ãµes PÃºblicas): Official Brazilian government procurement portal
- Contract data used under open data principles (Lei de Acesso Ã  InformaÃ§Ã£o - LAI)

### Acknowledgments

- Inspired by [OperaÃ§Ã£o Serenata de Amor](https://serenata.ai/)
- Built with support from the Brazilian civic tech community

---

## ğŸ”— Resources

### Documentation
- [API Reference](docs/api/README.md) (planned)
- [Data Pipeline Guide](docs/pipeline/README.md) (planned)
- [Deployment Guide](docs/deployment/README.md) (planned)

### External Links
- [PNCP Portal](https://pncp.gov.br/)
- [Lei 14.133/2021](http://www.planalto.gov.br/ccivil_03/_ato2019-2022/2021/lei/L14133.htm) (Brazilian procurement law)
- [TCU Open Data](https://portal.tcu.gov.br/dados-abertos/)

### Related Projects
- [Querido DiÃ¡rio](https://queridodiario.ok.org.br/) - Official gazette monitoring
- [Brasil.IO](https://brasil.io/) - Brazilian open datasets
- [Serenata de Amor](https://serenata.ai/) - Congressional expense auditing

---

<div align="center">

**Built with â¤ï¸ for transparency and civic participation**

[Report Bug](https://github.com/luansievers/farol/issues) Â· [Request Feature](https://github.com/luansievers/farol/issues) Â· [Contribute](CONTRIBUTING.md)

</div>
